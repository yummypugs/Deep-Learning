{"cells":[{"cell_type":"markdown","metadata":{"id":"LYk0Nm47InJ2"},"source":["## Autoencoders and GAN-s\n","\n","An obvious follow up of the question raised by representation learning is, whether we can use **unsupervised learning** techniques to learn **good representations of data**.\n","\n","This is all the more important, since in most cases we have **exponentially more raw data then labeled data**, so if we could pre-train our models on a broad raw dataset with unsupervised techniques, we could learn a lot about the world.\n","\n","In fact some scholars, notably [Yann LeCun](https://en.wikipedia.org/wiki/Yann_LeCun) argues that enabling broad scale unsupervised learning is the key to general intelligence.\n","\n","<img src=\"https://i2.wp.com/syncedreview.com/wp-content/uploads/2019/02/image-1a.png?resize=784%2C502&ssl=1\" width=70%>\n","\n","(There are also deep connections between un/self supervised learning and theories of mind, see eg. the theory of [predictive coding](https://en.wikipedia.org/wiki/Predictive_coding).)\n","\n","### Sidenote: [\"The Ganfather\"](https://www.technologyreview.com/s/610253/the-ganfather-the-man-whos-given-machines-the-gift-of-imagination/)\n","\n","In the field of unsupervised learning [Ian Goodfellow](https://en.wikipedia.org/wiki/Ian_Goodfellow) made great contributions with the elaboration of the GAN architecture. LeCun attributes him with the start of the \"Generative Revolution\" inside the DL field.\n","\n","<a href=\"https://www.deeplearningitalia.com/wp-content/uploads/2018/03/56180123458e517763fae26da757a924.jpg\"><img src=\"https://drive.google.com/uc?export=view&id=1DGE58IvyDD8GvXPg13acRF56Y9F_ac3P\" width=400 heigth=400></a>\n","\n","His in-depth [\"Deep Learning Book\"](https://www.deeplearningbook.org/) became somewhat of a canonical work, definitely worth reading.\n","\n","### Architecture of AEs and GANs\n","\n","The first widespread unsupervised neural models were the so called autoencoders.\n","\n","Autoencoders are unsupervised, or more properly **self-supervised learning models** that are trained to reconstruct the original data (with some noise or as sampling from a data distribution).\n","\n","\"According to the history provided in Schmidhuber, [\"Deep learning in neural networks: an overview,\", Neural Networks (2015)](https://arxiv.org/abs/1404.7828), auto-encoders were proposed as a method for unsupervised pre-training in Ballard, \"Modular learning in neural networks,\" Proceedings AAAI (1987). It's not clear if that's the first time auto-encoders were used, however; it's just the first time that they were used for the purpose of pre-training ANNs.\" ([soruce](https://stats.stackexchange.com/questions/238381/what-is-the-origin-of-the-autoencoder-neural-networks))\n","\n","Nowdays the purpose of this exercise is not pre-training (since \"depth\" is more or less conquered), but to learn dense \"semantic\" representations of the data.\n","\n","The big \"trick\" in autoencoders is the usage of the right objective and learning setting, since in the [words of Francois Chollet](https://blog.keras.io/building-autoencoders-in-keras.html):\n","\n","\"In order to get self-supervised models to **learn interesting features**, you have to come up with an interesting **synthetic target and loss function**, and that's where problems arise: **merely learning to reconstruct your input in minute detail** might **not** be the **right choice** here. At this point there is significant evidence that focusing on the **reconstruction** of a picture at the **pixel level**, for instance, is not conductive to learning interesting, abstract features of the kind that label-supervized learning induces (where targets are fairly abstract concepts \"invented\" by humans such as \"dog\", \"car\"...). In fact, one may argue that the **best features** in this regard are those that are the **worst at exact input reconstruction** while achieving high performance on the main task that you are interested in (classification, localization, etc).\"\n","\n","Because of the **limitations of Autoencoders**, [Goodfellow et al.](https://arxiv.org/abs/1406.2661) came up with the idea of a \"Generative adversarial network\" (GAN) **training regime**, whereby a **generative (forger) network** is **trained jointly** with a **\"discriminator\" network**, which **provides the (inverse) gradients**.\n","\n","Let's discuss these models in detail!"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-04-23T14:01:13.611931Z","start_time":"2019-04-23T14:01:13.587987Z"},"id":"qpwlFeB-InJ3","outputId":"14ecfcfc-b387-420f-95f0-682c19e9f588"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py:724: UserWarning: Consider using IPython.display.IFrame instead\n","  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"]},{"data":{"text/html":["<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vTeO6wBbmDp4pCyEqd9VPRIdqZ_nV__cPbr83ofA41mtnR5MZXMaQf1-NBnfKpYcxJqcgnHdsSoll0G/embed?start=false&loop=true&delayms=60000\" frameborder=\"0\" width=\"960\" height=\"569\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>"],"text/plain":["<IPython.core.display.HTML object>"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["from IPython.display import HTML\n","\n","HTML('<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vTeO6wBbmDp4pCyEqd9VPRIdqZ_nV__cPbr83ofA41mtnR5MZXMaQf1-NBnfKpYcxJqcgnHdsSoll0G/embed?start=false&loop=true&delayms=60000\" frameborder=\"0\" width=\"960\" height=\"569\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>')"]},{"cell_type":"markdown","source":["Decoder is the generater in an autoencoder\n","\n","VA's drawing noise within the bottleneck, but its very similar to the denoising autoencoder.\n","\n","Autoencoder --> denoising autoencoder --> variational autoencoder\n","\n","\n","Generative AAdversarial Network: one winner one loser, competative game situation"],"metadata":{"id":"XIG7WEn1MN61"}},{"cell_type":"markdown","metadata":{"id":"tQwm06gFInJ4"},"source":["### GAN Objective function\n","\n","#### Discriminator\n","<img src=\"https://miro.medium.com/max/700/1*FbQLpEVQKsMSK-c7_5KcWw.png\" width=65%>\n","\n","\n","#### Generator\n","<img src=\"https://miro.medium.com/max/700/1*KNgvzgz3FXQRbFWid_ZNUA.png\" width=40%>\n"]},{"cell_type":"markdown","metadata":{"id":"mNn4i9ALInJ4"},"source":["### What can they be good for?\n","\n","- GAN-s are also capable of acting on video streams\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-04-24T17:28:24.709655Z","start_time":"2019-04-24T17:28:24.687680Z"},"scrolled":true,"id":"TEe7yt47InJ5","outputId":"2e7b68e7-0484-468c-c4f1-248df538d8d7"},"outputs":[{"data":{"text/html":["<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Nq2xvsVojVo\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"],"text/plain":["<IPython.core.display.HTML object>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["from IPython.display import HTML\n","HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Nq2xvsVojVo\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"]},{"cell_type":"markdown","metadata":{"id":"Ae_QoOSGInJ5"},"source":["- It can handle acoustic inputs also, see for example these [voice cloning experiments](https://audiodemos.github.io/)\n","- It can enhance creativity"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-04-24T17:37:32.476048Z","start_time":"2019-04-24T17:37:32.461632Z"},"scrolled":true,"id":"phsoaQs8InJ5","outputId":"9e10aac1-a81c-4e75-8845-798aaa27a3f5"},"outputs":[{"data":{"text/html":["<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hW1_Sidq3m8\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"],"text/plain":["<IPython.core.display.HTML object>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["from IPython.display import HTML\n","HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hW1_Sidq3m8\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"]},{"cell_type":"markdown","metadata":{"id":"jm3LMEx7InJ5"},"source":["**More generally:**\n","\n","- New instance generation (hopefully in a controlled manner)\n","- Input for longer (classifier) pipelines\n","- Similarity search, clustering\n","...and many more things that is only bounded by creativity. :-)\n","\n","### Play with GANs\n","\n","There is a very nice recent visualization tool, [Play with Generated Adversarial Networks (GANs) in your browser!\n","](https://poloclub.github.io/ganlab/)\n","\n","Since the dynamics of GAN training is non  trivial, it is worth studying.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VkwzT9BLInJ5"},"source":["### The latet twist - Diffusion models\n","\n","In the latest development, a \"new\" contender in becoming state of the art of image an video generation models and text to image\n","\n","\n","<img src=\"http://drive.google.com/uc?export=view&id=1eUdVGL1ua8PwR__hZhyBn60hgJYxCosy\" width=600 heigth=600>\n","\n","\n","\n","[Introduction to diffusion models\n","](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)\n","\n","\n","\n","Drift diffusion models will be covered in much more detail in the AI- the Frontier Class\n","\n","See also\n","\n","here [Diffusion model based text to image by Google\n","](https://imagen.research.google/)\n","\n","Here, [Diffusion model based text to image by Hugging Face\n","](https://huggingface.co/CompVis/stable-diffusion)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U1q_Zg63InJ5"},"source":["### Conclusions\n","\n","The generative paradigm shift is considered one of the frontiers of AI (together with reinforcement learning, \"zero shot\" and \"multi task\" learning - to name a few). It is well worth watching this space!"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}