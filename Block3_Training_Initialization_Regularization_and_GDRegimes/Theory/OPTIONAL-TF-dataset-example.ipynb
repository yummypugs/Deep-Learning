{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cHToDxz6WMb_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback\n",
    "import gzip\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FMjDEdRFTA84",
    "outputId": "09c2e8f7-e106-4df7-b9af-b1de19b2bf2f"
   },
   "outputs": [],
   "source": [
    "def create_dir(dir_path):\n",
    "\n",
    "  # Check whether the specified path exists or not\n",
    "  isExist = os.path.exists(dir_path)\n",
    "\n",
    "  if not isExist:\n",
    "    \n",
    "    # Create a new directory because it does not exist \n",
    "    os.makedirs(dir_path)\n",
    "    print(f\"{dir_path} directory is created!\")\n",
    "\n",
    "\n",
    "root_path = './mnist_images'\n",
    "train_path = os.path.join(root_path, \"train\")\n",
    "test_path = os.path.join(root_path, \"test\")\n",
    "\n",
    "create_dir(root_path)\n",
    "create_dir(train_path)\n",
    "create_dir(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2qnPA-RGW3ye",
    "outputId": "446e53b1-6c2b-4eee-cc6c-6a16fd65863f"
   },
   "outputs": [],
   "source": [
    "train, test= tf.keras.datasets.mnist.load_data(\n",
    "    path='mnist.npz'\n",
    ")\n",
    "train_set, train_lables = train\n",
    "test_set, test_lables = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zEpCm3imXchb",
    "outputId": "133b2bcf-e27e-446e-9069-79475c505d20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train images to file...\n",
      "0 image was processed\n",
      "100 image was processed\n",
      "200 image was processed\n",
      "300 image was processed\n",
      "400 image was processed\n",
      "500 image was processed\n",
      "600 image was processed\n",
      "700 image was processed\n",
      "800 image was processed\n",
      "900 image was processed\n",
      "Writing test images to file...\n",
      "0 image was processed\n",
      "100 image was processed\n"
     ]
    }
   ],
   "source": [
    "def write_dataset_to_files(target_dir_path, X, y):\n",
    "  df = pd.DataFrame(columns=[\"file_name\", \"label\"])\n",
    "  for i_idx, x in enumerate(X):\n",
    "    img_name = \"_\".join([\"img\", str(i_idx)]) + '.jpg'\n",
    "    img_path = os.path.join(target_dir_path, img_name)\n",
    "    if i_idx % 100 == 0:\n",
    "      print(f\"{str(i_idx)} image was processed\")\n",
    "    plt.imsave(img_path, x)\n",
    "    df = df.append({\"file_name\": img_name, \"label\": y[i_idx] }, ignore_index=True)\n",
    "  labels_path = os.path.join(target_dir_path,\"labels.csv\")\n",
    "  df.to_csv(labels_path, index=False)\n",
    "  return labels_path\n",
    "\n",
    "print('Writing train images to file...')\n",
    "train_labels_path = write_dataset_to_files(train_path, train_set[:1000], train_lables[:1000])\n",
    "print('Writing test images to file...')\n",
    "test_labels_path = write_dataset_to_files(test_path, test_set[:200], test_lables[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "XuMenHWPen-N",
    "outputId": "4dfa8227-16a8-4e55-d32f-fb397ee33dfd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_0.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_2.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_4.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_name  label\n",
       "0  img_0.jpg      5\n",
       "1  img_1.jpg      0\n",
       "2  img_2.jpg      4\n",
       "3  img_3.jpg      1\n",
       "4  img_4.jpg      9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_df = pd.read_csv(train_labels_path)\n",
    "test_labels_df = pd.read_csv(test_labels_path)\n",
    "\n",
    "train_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "CZog7Nj3jTRW"
   },
   "outputs": [],
   "source": [
    "train_file_names = train_labels_df[\"file_name\"].values\n",
    "train_labels = train_labels_df[\"label\"].values\n",
    "\n",
    "test_file_names = test_labels_df[\"file_name\"].values\n",
    "test_labels = test_labels_df[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vNj1vrd_hjAQ",
    "outputId": "66658f02-82b9-4815-a993-fb3ef606a5ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 08:53:56.134289: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-22 08:53:56.134331: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-22 08:53:56.134359: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (adrian-Latitude-5491): /proc/driver/nvidia/version does not exist\n",
      "2022-02-22 08:53:56.134747: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_image(img_file, label):\n",
    "  image_path = train_path + '/' + img_file\n",
    "  image = tf.io.read_file(image_path)\n",
    "  image = tf.image.decode_image(image, channels=1, dtype=tf.float32)\n",
    "  return image, label\n",
    "\n",
    "def augment(image, label):\n",
    "  # do image augmentation here\n",
    "  return image, label\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((train_file_names, train_labels)) # similar to zip()\n",
    "\n",
    "ds_train = ds_train.map(read_image).map(augment).batch(64)\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_oBsIDL6j2gE",
    "outputId": "1ef05fe5-188e-4471-903a-3be7ad4e7add"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 16)        160       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                62730     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,530\n",
      "Trainable params: 67,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  layers.Input((28,28,1)),\n",
    "  layers.Conv2D(16, 3, padding=\"same\"),\n",
    "  layers.Conv2D(32, 3, padding=\"same\"),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(10),           \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    loss = [tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)],\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UxgylS3onQ7Z",
    "outputId": "a478c233-9f5a-42df-e5be-36180ff0802a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 1s 25ms/step - loss: 1.8328 - accuracy: 0.5100\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.7263 - accuracy: 0.8000\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4493 - accuracy: 0.8670\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3721 - accuracy: 0.8870\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3204 - accuracy: 0.9130\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.2640 - accuracy: 0.9280\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2062 - accuracy: 0.9460\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1753 - accuracy: 0.9520\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1424 - accuracy: 0.9650\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.1119 - accuracy: 0.9730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f82cd1375e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_train, epochs=10, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tf_data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv_ml",
   "language": "python",
   "name": "venv_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
